{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","metadata":{"id":"HbPApI7pbK7W","outputId":"e0b3c69b-f5bf-4abf-9e20-f58e2ec2e938","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671290634275,"user_tz":180,"elapsed":5612,"user":{"displayName":"Davi de Paula Oliveira","userId":"17718592585137256355"}}},"source":["!pip install git+https://github.com/canesche/nvcc4jupyter.git\n","!git clone https://github.com/canesche/nvcc4jupyter\n","%load_ext nvcc_plugin"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/canesche/nvcc4jupyter.git\n","  Cloning https://github.com/canesche/nvcc4jupyter.git to /tmp/pip-req-build-9i1ea382\n","  Running command git clone -q https://github.com/canesche/nvcc4jupyter.git /tmp/pip-req-build-9i1ea382\n","fatal: destination path 'nvcc4jupyter' already exists and is not an empty directory.\n","The nvcc_plugin extension is already loaded. To reload it, use:\n","  %reload_ext nvcc_plugin\n"]}]},{"cell_type":"markdown","metadata":{"id":"sp2gpshU9U1m"},"source":["\n","Considere que desejamos gerar um array B através de um array A de mesmo tamanho, de modo que, cada elemento `B[i]` é dado pela soma do elemento `A[i]` mais os `r` elementos anteriores à posição `i` em A mais os `r` elementos posteriores, ou seja:\n","```\n","for(j=i-r; j<=i+r; j++)\n","    B[i]+=A[j]\n","```\n","O código dado a seguir já faz o cálculo do array B (armazenado em `bHost`) de forma sequencial. Escreva um kernel CUDA, bem como todo o restante do código necessário para executá-lo, de modo a permitir o cálculo de B de forma paralela.\n","\n","As posições inválidas no início e final do array A devem ser simplesmente descartadas durante a soma, ou seja, para cálculo de `B[10]` com `r=32`, o resultado será a soma dos elementos de `A[0]` até `A[42]`.\n","\n","Se atente para os seguinte requisitos:\n","* O cálculo dos elementos de B deve ser realizado de forma paralela;\n","* A memória compartilhada da GPU deve ser utilizada de forma a deixar a operação mais eficiente;\n","* O código deve tratar corretamente arrays grandes divididos em mais de um bloco.\n","\n","Dicas:\n","* O código abaixo utiliza a constante `RANGE` para definir o valor de `r` e a constante `BLOCKSIZE` para definir o tamanho de cada bloco do grid;\n","* Por simplicidade, você pode considerar que o tamanho do array A será sempre múltiplo de `BLOCKSIZE`;\n","* Considere também que o tamanho de `r` será no máximo igual à metade de `BLOCKSIZE`, ou seja, o array alocado na memória compartilhada terá tamanho igual a `2*BLOCKSIZE`, no máximo.\n","* A estratégia utilizada pela versão sequencial de testar cada posição (para descobrir se é válida) não é ótima. Muitas comparações desnecessárias são realizadas ao calcular as posições intermediárias. Na versão paralela, é melhor preecher as posições inválidas com o valor 0 (zero) ao copiar os dados para a memória compartilhada."]},{"cell_type":"code","metadata":{"id":"x7rUJaOP0hfD","outputId":"794bcc9f-704d-48f9-b469-8774f1edfa55","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671290681248,"user_tz":180,"elapsed":3447,"user":{"displayName":"Davi de Paula Oliveira","userId":"17718592585137256355"}}},"source":["%%gpu\n","#include<stdio.h>\n","#include<cuda.h>\n","\n","#define BLOCKSIZE 1024  //threads por bloco\n","#define RANGE 256       //deslocamento utilizado para cálculo de B\n","\n","void initArray(int *a, int n) {\n","    for (int i =0; i<n; ++i) \n","        a[i]=i;\n","}\n","\n","void printArray(int *a, int n) {\n","    int maxPrint=20;\n","    for (int i =0; i<(n>maxPrint ? maxPrint : n); ++i) \n","        printf(\"%3d \",a[i]);\n","    if (n>maxPrint) printf(\"... (array truncado)\");\n","    printf(\"\\n\");\n","}\n","\n","bool checkArray(int *a, int *b, int n) {\n","    for (int i =0; i<n; ++i) \n","        if (a[i]!=b[i])\n","            return false;\n","    return true;\n","}\n","\n","void execHost(int *A, int n, int *B) {\n","    for(int i=0; i<n; i++) {\n","        int soma=0;\n","        for(int j=i-RANGE; j<=i+RANGE; j++)\n","            if(j >= 0 && j<n)\n","                soma+=A[j];\n","        B[i]=soma;\n","    }\n","}\n","\n","__global__\n","void execGPU(int *A, int n, int *B) {\n","    __shared__ int sA[2 * BLOCKSIZE];\n","\n","    int inicioBloco = blockIdx.x * blockDim.x;\n","    int fimBloco = (blockIdx.x + 1) * blockDim.x - 1;\n","    int idRelativo = threadIdx.x;\n","    int idGeral = blockIdx.x * blockDim.x + idRelativo;\n","\n","    sA[idRelativo + RANGE] = A[idGeral];\n","    \n","    if(idGeral - RANGE < 0)\n","        sA[idRelativo] = 0;\n","    else if(idGeral - RANGE < inicioBloco)\n","        sA[idRelativo] = A[idGeral - RANGE];\n","    \n","    if(idGeral + RANGE >= n)\n","        sA[idRelativo + 2 * RANGE] = 0;\n","    else if(idGeral + RANGE > fimBloco)\n","        sA[idRelativo + 2 * RANGE] = A[idGeral + RANGE];\n","\n","    __syncthreads();\n","\n","    int soma = 0;\n","        \n","    for(int i = idRelativo; i <= idRelativo + 2 * RANGE; i++)\n","        soma += sA[i];\n","        \n","    B[idGeral] = soma;\n","}\n","\n","int main() {\n","    int size=1<<20;             //tamanho dos arrays A e B\n","    int dsize=size*sizeof(int); //tamanho dos dados\n","    int *a;\n","    int *aGPU;\n","    int *b;                     //array B a ser calculado na GPU\n","    int *bGPU;\n","    int *bHost;                 //array B calculado na CPU\n","    a=(int*)malloc(dsize);\n","    b=(int*)malloc(dsize);\n","    bHost=(int*)malloc(dsize);\n","    \n","    initArray(a,size);\n","    printf(\"    A: \");\n","    printArray(a,size);\n","\n","    cudaMalloc((void **) &aGPU, dsize);\n","    cudaMalloc((void **) &bGPU, dsize);\n","    cudaMemcpy(aGPU, a, dsize, cudaMemcpyHostToDevice);\n","    printf(\"B-GPU: \");\n","    execGPU<<<size/BLOCKSIZE,BLOCKSIZE>>>(aGPU, size, bGPU);\n","    cudaMemcpy(b, bGPU, dsize, cudaMemcpyDeviceToHost);\n","    printArray(b,size);\n","    cudaFree(aGPU);\n","    cudaFree(bGPU); \n","\n","    printf(\"B-CPU: \");\n","    execHost(a, size, bHost);\n","    printArray(bHost,size);\n","\n","    if (checkArray(b,bHost,size))\n","        printf(\"Resultados iguais\\n\");\n","    else\n","        printf(\"Resultados diferentes\\n\");\n","\n","    free(bHost);\n","    free(a);\n","    free(b);\n","\n","    return 0;\n","}"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["    A:   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19 ... (array truncado)\n","B-GPU: 32896 33153 33411 33670 33930 34191 34453 34716 34980 35245 35511 35778 36046 36315 36585 36856 37128 37401 37675 37950 ... (array truncado)\n","B-CPU: 32896 33153 33411 33670 33930 34191 34453 34716 34980 35245 35511 35778 36046 36315 36585 36856 37128 37401 37675 37950 ... (array truncado)\n","Resultados iguais\n","\n"]}]}]}